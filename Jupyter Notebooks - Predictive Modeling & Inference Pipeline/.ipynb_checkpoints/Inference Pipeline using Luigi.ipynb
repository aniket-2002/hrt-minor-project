{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline for Prediction of Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last notebook, I tested the Ensemble Technique using Max Voting which will give me better results after combining votes from 3 of my best models - SVM, Logistic and Random Forest\n",
    "\n",
    "- In this Notebook, I will be create an **Inference Pipeline using Ensemble of 3 best models KNN, Logistic and Random Forest** models saved with the best hyperparameters. \n",
    "\n",
    "\n",
    "- The input data will need to be **converted to dummy variables** for new data and **reordered to keep it in same order** as it was during training. Then I also need to **scale features using MinMax Scaling** before predicting the output using the 3 models. \n",
    "\n",
    "\n",
    "- **Once I have the output from the 3 models, I can use any ensembling technique to get the final prediction. I will be using a Max voting appraoch here**. \n",
    "\n",
    "\n",
    "- Once the Pipeline is ready, I will **integrate it with the Streamlit App and Deploy it using Docker & Heroku** so anyone can make predictions using the APP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import statistics\n",
    "import streamlit as st\n",
    "import os\n",
    "#from sklearn.externals import joblib \n",
    "from features_utils import *\n",
    "\n",
    "\n",
    "class DataPreprocessing(luigi.Task):\n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('featuresDP.csv')\n",
    "    \n",
    "    def run(self):\n",
    "        df_pred = pd.read_csv('./inputData.csv', index_col=[0])\n",
    "        \n",
    "        lookup_cols = ['sex', 'chest_pain_type','fasting_blood_sugar', 'resting_ECG',\n",
    "               'exercise_induced_angina', 'slope','thalium_stress']\n",
    "        for col in lookup_cols:\n",
    "            df_pred[col] = df_pred[col].apply(lambda x: cat_lookup[x])\n",
    "            \n",
    "        #cat_dummies = [col for col in original_features\n",
    "        #      if '_' in col and '_'.join(col.split('_')[:-1]) in categorical_cols]\n",
    "        \n",
    "        df_heart = pd.get_dummies(df_pred, prefix_sep='_', columns=categorical_cols)\n",
    "                \n",
    "        df_heart.to_csv(self.output().path)\n",
    "        \n",
    "        \n",
    "    \n",
    "class FeatureEngineering(luigi.Task):\n",
    "    \n",
    "    def requires(self):\n",
    "        yield DataPreprocessing()\n",
    "        \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('featuresFE.csv')\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        df_heart= pd.read_csv(DataPreprocessing().output().path,  index_col=[0])\n",
    "        ## Remove additional columns\n",
    "        for col in df_heart.columns:\n",
    "            if(('_' in col) and ('_'.join(col.split('_')[:-1]) in categorical_cols) and col not in cat_dummies):\n",
    "                print('Removing additional feature {} not used in training'.format(col))\n",
    "                df_heart.drop(columns=[col], axis=1, inplace=True)\n",
    "                \n",
    "        #add missing columns\n",
    "        for col in cat_dummies:\n",
    "            if col not in df_heart.columns:\n",
    "                print('Adding missing feature {}'.format(col))\n",
    "                df_heart[col] = 0\n",
    "        \n",
    "        #feature scaling \n",
    "        \n",
    "        scalerfile = './Models/scaler.sav'\n",
    "        scaler = pickle.load(open(scalerfile, 'rb'))\n",
    "        features_SS = scaler.transform(df_heart)\n",
    "        \n",
    "        features_SS = pd.DataFrame(features_SS, columns=df_heart.columns)\n",
    "        features_SS.to_csv(self.output().path)\n",
    "        \n",
    "        \n",
    "class PredictEnsemble(luigi.Task):\n",
    "    def requires(self):\n",
    "        yield FeatureEngineering()\n",
    "        \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('prediction.txt')\n",
    "    \n",
    "    def run(self):\n",
    "        features_SS = pd.read_csv(FeatureEngineering().output().path,  index_col=[0])\n",
    "        #selecting features for each of 3 models\n",
    "        features_RF = features_SS[original_features]\n",
    "        features_Logit = features_SS[selected_features]\n",
    "        features_knn = features_SS[original_features]\n",
    "        \n",
    "        # load models from directory \n",
    "        rf = pickle.load(open('./Models/RandomForestclf.pkl', 'rb'))\n",
    "        logit = pickle.load(open('./Models/LogisticRegression.pkl', 'rb'))\n",
    "        knn = pickle.load(open('./Models/KNNClassifier.pkl', 'rb'))\n",
    "        \n",
    "        pred_rf = rf.predict(features_RF)\n",
    "        pred_logit = logit.predict(features_Logit)\n",
    "        pred_knn = knn.predict(features_knn)\n",
    "        #Ensemble Max Voting Prediction\n",
    "        print('RF :' ,pred_rf)\n",
    "        print('logit :', pred_logit)\n",
    "        print('knn :', pred_knn)\n",
    "        ensemble_pred = statistics.mode([int(pred_logit), int(pred_knn), int(pred_rf)])\n",
    "        ensemble_diagnostic = ''\n",
    "        if ensemble_pred == 0:\n",
    "            ensemble_diagnostic = 'does not have a Heart Disease'\n",
    "        else:\n",
    "            ensemble_diagnostic = 'might have a Heart Disease. Please perform further tests.'\n",
    "        with self.output().open('w') as pred_file:\n",
    "            pred_file.write(ensemble_diagnostic)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    luigi.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
